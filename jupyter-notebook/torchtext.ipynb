{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchtext\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceField(torchtext.data.Field):\n",
    "    \"\"\" Wrapper class of torchtext.data.Field that forces batch_first and include_lengths to be True. \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        logger = logging.getLogger(__name__)\n",
    "\n",
    "        if kwargs.get('batch_first') is False:\n",
    "            logger.warning(\"Option batch_first has to be set to use pytorch-seq2seq.  Changed to True.\")\n",
    "        kwargs['batch_first'] = True\n",
    "        if kwargs.get('include_lengths') is False:\n",
    "            logger.warning(\"Option include_lengths has to be set to use pytorch-seq2seq.  Changed to True.\")\n",
    "        kwargs['include_lengths'] = True\n",
    "\n",
    "        super(SourceField, self).__init__(**kwargs)\n",
    "\n",
    "class TargetField(torchtext.data.Field):\n",
    "    \"\"\" Wrapper class of torchtext.data.Field that forces batch_first to be True and prepend <sos> and append <eos> to sequences in preprocessing step.\n",
    "\n",
    "    Attributes:\n",
    "        sos_id: index of the start of sentence symbol\n",
    "        eos_id: index of the end of sentence symbol\n",
    "    \"\"\"\n",
    "\n",
    "    SYM_SOS = '<sos>'\n",
    "    SYM_EOS = '<eos>'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        logger = logging.getLogger(__name__)\n",
    "\n",
    "        if kwargs.get('batch_first') == False:\n",
    "            logger.warning(\"Option batch_first has to be set to use pytorch-seq2seq.  Changed to True.\")\n",
    "        kwargs['batch_first'] = True\n",
    "        if kwargs.get('preprocessing') is None:\n",
    "            kwargs['preprocessing'] = lambda seq: [self.SYM_SOS] + seq + [self.SYM_EOS]\n",
    "        else:\n",
    "            func = kwargs['preprocessing']\n",
    "            kwargs['preprocessing'] = lambda seq: [self.SYM_SOS] + func(seq) + [self.SYM_EOS]\n",
    "\n",
    "        self.sos_id = None\n",
    "        self.eos_id = None\n",
    "        super(TargetField, self).__init__(**kwargs)\n",
    "\n",
    "    def build_vocab(self, *args, **kwargs):\n",
    "        super(TargetField, self).build_vocab(*args, **kwargs)\n",
    "        self.sos_id = self.vocab.stoi[self.SYM_SOS]\n",
    "        self.eos_id = self.vocab.stoi[self.SYM_EOS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_field=torchtext.data.Field()\n",
    "tgt_field=torchtext.data.Field(init_token='<BOS>',eos_token='<EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.field.Field at 0x1107a8f28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example=torchtext.data.Example.fromlist([\"a b c\",\"d e f\"],[('src',src_field),('tgt',tgt_field)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'e', 'f']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(torchtext.data.Dataset):\n",
    "    \"\"\"Defines a dataset for machine translation.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return torchtext.data.interleave_keys(len(ex.src), len(ex.trg))\n",
    "\n",
    "    def __init__(self, path, exts, fields, **kwargs):\n",
    "        \"\"\"Create a TranslationDataset given paths and fields.\n",
    "        Arguments:\n",
    "            path: Common prefix of paths to the data files for both languages.\n",
    "            exts: A tuple containing the extension to path for each language.\n",
    "            fields: A tuple containing the fields that will be used for data\n",
    "                in each language.\n",
    "            Remaining keyword arguments: Passed to the constructor of\n",
    "                data.Dataset.\n",
    "        \"\"\"\n",
    "        if not isinstance(fields[0], (tuple, list)):\n",
    "            fields = [('src', fields[0]), ('trg', fields[1])]\n",
    "\n",
    "        src_path, trg_path = tuple(os.path.expanduser(path + x) for x in exts)\n",
    "\n",
    "        examples = []\n",
    "        with open(src_path) as src_file, open(trg_path) as trg_file:\n",
    "            for src_line, trg_line in zip(src_file, trg_file):\n",
    "                src_line, trg_line = src_line.strip(), trg_line.strip()\n",
    "                if src_line != '' and trg_line != '':\n",
    "                    examples.append(torchtext.data.Example.fromlist(\n",
    "                        [src_line, trg_line], fields))\n",
    "        total_len=len(examples)\n",
    "        super(TranslationDataset, self).__init__(examples, fields, **kwargs)\n",
    "        \n",
    "        self.coverage=len(self.examples)/total_len\n",
    "        \n",
    "    @classmethod\n",
    "    def splits(cls, exts, fields, root='.data',\n",
    "               train='train', validation='val', test='test', **kwargs):\n",
    "        \"\"\"Create dataset objects for splits of a TranslationDataset.\n",
    "        Arguments:\n",
    "            root: Root dataset storage directory. Default is '.data'.\n",
    "            exts: A tuple containing the extension to path for each language.\n",
    "            fields: A tuple containing the fields that will be used for data\n",
    "                in each language.\n",
    "            train: The prefix of the train data. Default: 'train'.\n",
    "            validation: The prefix of the validation data. Default: 'val'.\n",
    "            test: The prefix of the test data. Default: 'test'.\n",
    "            Remaining keyword arguments: Passed to the splits method of\n",
    "                Dataset.\n",
    "        \"\"\"\n",
    "        path = cls.download(root)\n",
    "\n",
    "        train_data = None if train is None else cls(\n",
    "            os.path.join(path, train), exts, fields, **kwargs)\n",
    "        val_data = None if validation is None else cls(\n",
    "            os.path.join(path, validation), exts, fields, **kwargs)\n",
    "        test_data = None if test is None else cls(\n",
    "            os.path.join(path, test), exts, fields, **kwargs)\n",
    "        return tuple(d for d in (train_data, val_data, test_data)\n",
    "                     if d is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=100\n",
    "def sent_len_filter(example, maxlen=maxlen):\n",
    "    if len(example.src)<=maxlen and len(example.trg)<=maxlen:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=TranslationDataset(exts=('.cn1','.cn2'),\n",
    "                     fields=(src_field,tgt_field),\n",
    "                     path='../data/toy_reverse_chinese_numbers/train',\n",
    "                    filter_pred=sent_len_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_field.build_vocab()\n",
    "tgt_field.build_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=t.fields['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
       "            {'<pad>': 1, '<unk>': 0})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "it=torchtext.data.BucketIterator(batch_size=16,\n",
    "                                 dataset=t,\n",
    "                                 device=-1,\n",
    "                                 repeat=False,\n",
    "                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "it=iter(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    1     1     1     1     1     1     0     0     0     0     0     0     0\n",
       "\n",
       "Columns 13 to 15 \n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "    0     0     0\n",
       "[torch.LongTensor of size 44x16]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
